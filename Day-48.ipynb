{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdfd43d",
   "metadata": {},
   "source": [
    "# **Day - 48 : Preprocess Data with Sklearn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83985fd",
   "metadata": {},
   "source": [
    "*1.*\n",
    "\n",
    "*When training a model on a dataset, it is advisable to split the data into training and test sets. Why do we split data into training and test sets?* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5315d3",
   "metadata": {},
   "source": [
    ">We split data into training and test sets to check how well the model performs on unseen data.\n",
    "\n",
    ">>Training set: Used to teach the model.\n",
    "\n",
    ">>Test set: Used to evaluate how well the model generalizes to new, real-world data.\n",
    "\n",
    ">If you train and test on the same data, the model can memorize it and look perfect, but completely fail on new data. That’s like studying only past exam papers and then failing the actual test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbcd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>flower_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width flower_type\n",
       "0           5.1          3.5           1.4          0.2      setosa\n",
       "1           4.9          3.0           1.4          0.2      setosa\n",
       "2           4.7          3.2           1.3          0.2  versicolor\n",
       "3           4.6          3.1           1.5          0.2  versicolor\n",
       "4           5.0          3.6           1.4          0.2      setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Data/flower_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5843b",
   "metadata": {},
   "source": [
    "*2.*\n",
    "\n",
    "*Create a copy of the DataFrame. In supervised machine learning, the target variable is the variable that will be predicted using the other variables in the dataset. This target variable must be converted into numeric data type before fitting a model. Convert this target variable(flower_type) into numeric data type and separate the target column from the other variables. Write code to create two variables, x and y. X is the variable that will predict the target variable, y. Use scikit-learn's train_test_split() function to split the data into training and test sets. Make the test size to be 20% of the data set. Set the random_state parameter to 42. Check the shapes of the training and test sets. What is the purpose of the random_state parameter in the train_test_split() function?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb681aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63df939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>flower_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  flower_type\n",
       "0           5.1          3.5           1.4          0.2            0\n",
       "1           4.9          3.0           1.4          0.2            0\n",
       "2           4.7          3.2           1.3          0.2            1\n",
       "3           4.6          3.1           1.5          0.2            1\n",
       "4           5.0          3.6           1.4          0.2            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_copy[\"flower_type\"] = le.fit_transform(df_copy[\"flower_type\"])\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ea9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 4), (16,), (4, 4), (4,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_copy.drop(columns=[\"flower_type\"])\n",
    "\n",
    "y = df_copy[\"flower_type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee72e929",
   "metadata": {},
   "source": [
    "*3.*\n",
    "\n",
    "*Why is it important to standardize the data before fitting? Use Scikit-Learn's StandardScaler to standardize the features in the dataset (training and test sets).* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03181e75",
   "metadata": {},
   "source": [
    ">Standardizing data makes sure all features are on the same scale, so no single feature dominates just because it has bigger values. Models like SVM, KNN, and logistic regression are sensitive to feature scales—without standardizing, they can get confused and give bad results. It’s basically leveling the playing field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e761e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3782598 , -1.53281263, -0.23791548, -0.2773501 ],\n",
       "       [ 0.94301987,  1.25411943,  1.66540833,  1.94145069],\n",
       "       [-0.44974794, -0.1393466 ,  1.03096706, -0.2773501 ],\n",
       "       [-0.91400387, -0.97542622,  0.39652579, -0.2773501 ],\n",
       "       [ 1.63940377,  0.97542622,  1.66540833,  0.83205029],\n",
       "       [ 0.94301987,  1.25411943, -0.87235674,  1.94145069],\n",
       "       [-1.61038777, -1.25411943, -2.14123928, -1.38675049],\n",
       "       [-0.6818759 , -0.69673301, -0.87235674, -0.2773501 ],\n",
       "       [-0.21761997, -0.97542622,  0.39652579, -1.38675049],\n",
       "       [ 0.24663596,  0.97542622,  0.39652579,  0.83205029],\n",
       "       [ 0.014508  ,  0.41803981, -0.23791548, -0.2773501 ],\n",
       "       [-0.44974794, -1.25411943, -0.23791548, -1.38675049],\n",
       "       [ 0.014508  , -0.1393466 ,  0.39652579, -0.2773501 ],\n",
       "       [ 0.94301987,  0.69673301,  0.39652579, -0.2773501 ],\n",
       "       [ 1.87153173,  1.53281263, -1.50679801, -0.2773501 ],\n",
       "       [-0.91400387, -0.1393466 , -0.23791548,  0.83205029]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641a850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
